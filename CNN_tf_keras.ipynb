{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLQUsZeBm6IxsEYePgt06Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharv1813/colab_tuts/blob/main/CNN_tf_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0qHKEzLggTq-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes on CIFAR-10 Dataset in TensorFlow\n",
        "\n",
        "1. **Overview**:\n",
        "   - CIFAR-10 is a popular dataset used for image classification.\n",
        "   - It consists of **60,000 images** divided into **10 classes** (6,000 images per class).\n",
        "   - The images are **32x32 pixels in RGB color**.\n",
        "   - The dataset is split into **50,000 training images** and **10,000 test images**.\n",
        "\n",
        "2. **Classes**:\n",
        "   - The 10 classes in the CIFAR-10 dataset are:\n",
        "     1. Airplane\n",
        "     2. Automobile\n",
        "     3. Bird\n",
        "     4. Cat\n",
        "     5. Deer\n",
        "     6. Dog\n",
        "     7. Frog\n",
        "     8. Horse\n",
        "     9. Ship\n",
        "     10. Truck\n",
        "   - Each class is **mutually exclusive** (e.g., no image belongs to more than one class).\n",
        "\n",
        "\n",
        "\n",
        "4. **Data Format**:\n",
        "   - `x_train` and `x_test`: Arrays containing the image data, with shape `(num_samples, 32, 32, 3)`.\n",
        "   - `y_train` and `y_test`: Arrays containing the labels, with shape `(num_samples, 1)`.\n",
        "   - Images are represented as pixel values between 0 and 255.\n",
        "\n",
        "6. **Use Cases**:\n",
        "   - Commonly used for training and testing **image classification models**.\n",
        "   - Suitable for benchmarking various **machine learning and deep learning models**.\n",
        "\n",
        "7. **Challenges**:\n",
        "   - The dataset is relatively small, so models may easily overfit.\n",
        "   - Images have a small size (32x32), making it challenging to capture complex features.\n",
        "\n",
        "8. **Data Augmentation**:\n",
        "   - To improve model performance, data augmentation techniques such as flipping, rotation, and zooming are often applied.\n",
        "   - Example using `tf.keras.preprocessing.image.ImageDataGenerator`:\n",
        "     ```python\n",
        "     from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "     datagen = ImageDataGenerator(\n",
        "         rotation_range=15,\n",
        "         width_shift_range=0.1,\n",
        "         height_shift_range=0.1,\n",
        "         horizontal_flip=True\n",
        "     )\n",
        "     datagen.fit(x_train)\n",
        "     ```\n",
        "\n",
        "9. **Example Models**:\n",
        "   - Models like Convolutional Neural Networks (CNNs) are commonly used on CIFAR-10 due to the image data format.\n",
        "   - Pre-trained models (e.g., ResNet, VGG) can be fine-tuned on CIFAR-10 for better accuracy.\n",
        "\n",
        "10. **Performance Metrics**:\n",
        "    - **Accuracy** is the most commonly used metric for evaluating models on CIFAR-10.\n",
        "    - Other metrics, such as **precision**, **recall**, and **F1-score**, can be used for a more comprehensive evaluation.\n",
        "\n",
        "Let me know if you need specific code examples or explanations about any part!"
      ],
      "metadata": {
        "id": "SxKOSOJWieaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "zhMsGxjuirSl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "id": "P_P8raHWi4Gr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 3)), # bcz CNN so no need to flatten img at start\n",
        "        layers.Conv2D(32, 3, padding='valid', activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        layers.Conv2D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "esbevGqAi-j7",
        "outputId": "e3ab8f4d-2b2e-4914-abe0-0b4221262c01"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m131,136\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,034\u001b[0m (879.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,034</span> (879.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,034\u001b[0m (879.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,034</span> (879.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/10\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.3983 - loss: 1.6565\n",
            "Epoch 2/10\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.5247 - loss: 1.3322\n",
            "Epoch 3/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.5783 - loss: 1.2038\n",
            "Epoch 4/10\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.6121 - loss: 1.1057\n",
            "Epoch 5/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.6405 - loss: 1.0298\n",
            "Epoch 6/10\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.6622 - loss: 0.9701\n",
            "Epoch 7/10\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.6794 - loss: 0.9233\n",
            "Epoch 8/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.6978 - loss: 0.8749\n",
            "Epoch 9/10\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7116 - loss: 0.8315\n",
            "Epoch 10/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.7248 - loss: 0.7958\n",
            "157/157 - 1s - 5ms/step - accuracy: 0.7027 - loss: 0.8849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8849102258682251, 0.7027000188827515]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model using your function\n",
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(32, 3)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 5, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Conv2D(128, 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    outputs = layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ee41anB3lKHd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = my_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DevJaBZasKJN",
        "outputId": "f4767932-1c9f-47bb-bfa0-5d01a4ec8058"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 - 11s - 14ms/step - accuracy: 0.5137 - loss: 1.3620\n",
            "Epoch 2/10\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6797 - loss: 0.9165\n",
            "Epoch 3/10\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.7403 - loss: 0.7383\n",
            "Epoch 4/10\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.7790 - loss: 0.6288\n",
            "Epoch 5/10\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.8084 - loss: 0.5462\n",
            "Epoch 6/10\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8360 - loss: 0.4684\n",
            "Epoch 7/10\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.8628 - loss: 0.3942\n",
            "Epoch 8/10\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8883 - loss: 0.3292\n",
            "Epoch 9/10\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.9047 - loss: 0.2786\n",
            "Epoch 10/10\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.9270 - loss: 0.2238\n",
            "157/157 - 1s - 7ms/step - accuracy: 0.6961 - loss: 1.0983\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0983117818832397, 0.6960999965667725]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding regularizers to the model**"
      ],
      "metadata": {
        "id": "vTinKKPltAPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the data to the range [0, 1]\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Define the model with L2 regularization and Dropout\n",
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    # First Conv2D layer with L2 regularization and Batch Normalization\n",
        "    x = layers.Conv2D(32, 3, padding='same', kernel_regularizer=l2(0.01))(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    # Second Conv2D layer with L2 regularization and Batch Normalization\n",
        "    x = layers.Conv2D(64, 3, padding='same', kernel_regularizer=l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    # Third Conv2D layer with L2 regularization and Batch Normalization\n",
        "    x = layers.Conv2D(128, 3, kernel_regularizer=l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    # Dense layer with L2 regularization and Dropout\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "    x = layers.Dropout(0.5)(x)  # Dropout layer\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Dense(10)(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = my_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=150, verbose=2)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7p-cWAstEuy",
        "outputId": "979703e7-060e-4625-9a54-9b423d2fc479"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "782/782 - 12s - 15ms/step - accuracy: 0.4036 - loss: 3.0941\n",
            "Epoch 2/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5394 - loss: 1.8842\n",
            "Epoch 3/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5905 - loss: 1.5377\n",
            "Epoch 4/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6178 - loss: 1.3910\n",
            "Epoch 5/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.6363 - loss: 1.3096\n",
            "Epoch 6/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.6505 - loss: 1.2584\n",
            "Epoch 7/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.6560 - loss: 1.2364\n",
            "Epoch 8/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6726 - loss: 1.1930\n",
            "Epoch 9/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6782 - loss: 1.1804\n",
            "Epoch 10/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.6853 - loss: 1.1546\n",
            "Epoch 11/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.6938 - loss: 1.1404\n",
            "Epoch 12/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.6959 - loss: 1.1299\n",
            "Epoch 13/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7039 - loss: 1.1139\n",
            "Epoch 14/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7122 - loss: 1.0961\n",
            "Epoch 15/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.7151 - loss: 1.0830\n",
            "Epoch 16/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7222 - loss: 1.0705\n",
            "Epoch 17/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7256 - loss: 1.0664\n",
            "Epoch 18/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7319 - loss: 1.0555\n",
            "Epoch 19/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7332 - loss: 1.0465\n",
            "Epoch 20/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7413 - loss: 1.0254\n",
            "Epoch 21/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7433 - loss: 1.0228\n",
            "Epoch 22/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7455 - loss: 1.0184\n",
            "Epoch 23/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7500 - loss: 1.0099\n",
            "Epoch 24/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.7547 - loss: 1.0040\n",
            "Epoch 25/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.7563 - loss: 0.9939\n",
            "Epoch 26/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7595 - loss: 0.9865\n",
            "Epoch 27/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7649 - loss: 0.9795\n",
            "Epoch 28/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7661 - loss: 0.9752\n",
            "Epoch 29/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7685 - loss: 0.9681\n",
            "Epoch 30/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.7721 - loss: 0.9635\n",
            "Epoch 31/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7744 - loss: 0.9543\n",
            "Epoch 32/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7715 - loss: 0.9605\n",
            "Epoch 33/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7782 - loss: 0.9484\n",
            "Epoch 34/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7811 - loss: 0.9430\n",
            "Epoch 35/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.7840 - loss: 0.9429\n",
            "Epoch 36/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7837 - loss: 0.9367\n",
            "Epoch 37/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7858 - loss: 0.9297\n",
            "Epoch 38/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.7871 - loss: 0.9254\n",
            "Epoch 39/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.7906 - loss: 0.9215\n",
            "Epoch 40/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.7926 - loss: 0.9206\n",
            "Epoch 41/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7933 - loss: 0.9148\n",
            "Epoch 42/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.7953 - loss: 0.9117\n",
            "Epoch 43/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.7958 - loss: 0.9068\n",
            "Epoch 44/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.9086\n",
            "Epoch 45/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7978 - loss: 0.9001\n",
            "Epoch 46/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8013 - loss: 0.9029\n",
            "Epoch 47/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8062 - loss: 0.8875\n",
            "Epoch 48/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8052 - loss: 0.8907\n",
            "Epoch 49/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8086 - loss: 0.8800\n",
            "Epoch 50/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.8876\n",
            "Epoch 51/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8118 - loss: 0.8758\n",
            "Epoch 52/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8091 - loss: 0.8783\n",
            "Epoch 53/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8118 - loss: 0.8741\n",
            "Epoch 54/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8118 - loss: 0.8756\n",
            "Epoch 55/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8132 - loss: 0.8679\n",
            "Epoch 56/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8148 - loss: 0.8689\n",
            "Epoch 57/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8131 - loss: 0.8718\n",
            "Epoch 58/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8136 - loss: 0.8710\n",
            "Epoch 59/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8188 - loss: 0.8603\n",
            "Epoch 60/150\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.8211 - loss: 0.8512\n",
            "Epoch 61/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8182 - loss: 0.8577\n",
            "Epoch 62/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8191 - loss: 0.8602\n",
            "Epoch 63/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8213 - loss: 0.8558\n",
            "Epoch 64/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8241 - loss: 0.8458\n",
            "Epoch 65/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8233 - loss: 0.8509\n",
            "Epoch 66/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8276 - loss: 0.8419\n",
            "Epoch 67/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8270 - loss: 0.8448\n",
            "Epoch 68/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8247 - loss: 0.8491\n",
            "Epoch 69/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8250 - loss: 0.8480\n",
            "Epoch 70/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8279 - loss: 0.8397\n",
            "Epoch 71/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8312 - loss: 0.8421\n",
            "Epoch 72/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8288 - loss: 0.8390\n",
            "Epoch 73/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8289 - loss: 0.8419\n",
            "Epoch 74/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8308 - loss: 0.8375\n",
            "Epoch 75/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8341 - loss: 0.8278\n",
            "Epoch 76/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8307 - loss: 0.8417\n",
            "Epoch 77/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8324 - loss: 0.8352\n",
            "Epoch 78/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8363 - loss: 0.8244\n",
            "Epoch 79/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8341 - loss: 0.8293\n",
            "Epoch 80/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8319 - loss: 0.8345\n",
            "Epoch 81/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8345 - loss: 0.8309\n",
            "Epoch 82/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8367 - loss: 0.8234\n",
            "Epoch 83/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8357 - loss: 0.8286\n",
            "Epoch 84/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8366 - loss: 0.8199\n",
            "Epoch 85/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8393 - loss: 0.8203\n",
            "Epoch 86/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8374 - loss: 0.8174\n",
            "Epoch 87/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8376 - loss: 0.8247\n",
            "Epoch 88/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8410 - loss: 0.8138\n",
            "Epoch 89/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8383 - loss: 0.8192\n",
            "Epoch 90/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8387 - loss: 0.8213\n",
            "Epoch 91/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8413 - loss: 0.8158\n",
            "Epoch 92/150\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.8411 - loss: 0.8123\n",
            "Epoch 93/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8430 - loss: 0.8096\n",
            "Epoch 94/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8411 - loss: 0.8161\n",
            "Epoch 95/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8449 - loss: 0.8104\n",
            "Epoch 96/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8470 - loss: 0.8024\n",
            "Epoch 97/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8425 - loss: 0.8167\n",
            "Epoch 98/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8449 - loss: 0.8062\n",
            "Epoch 99/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8448 - loss: 0.8096\n",
            "Epoch 100/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8443 - loss: 0.8115\n",
            "Epoch 101/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8465 - loss: 0.8040\n",
            "Epoch 102/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8440 - loss: 0.8125\n",
            "Epoch 103/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8458 - loss: 0.8065\n",
            "Epoch 104/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8465 - loss: 0.8048\n",
            "Epoch 105/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8475 - loss: 0.8064\n",
            "Epoch 106/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8491 - loss: 0.8010\n",
            "Epoch 107/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8497 - loss: 0.7982\n",
            "Epoch 108/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8483 - loss: 0.8015\n",
            "Epoch 109/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8508 - loss: 0.7952\n",
            "Epoch 110/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8479 - loss: 0.7988\n",
            "Epoch 111/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8490 - loss: 0.7988\n",
            "Epoch 112/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8493 - loss: 0.7978\n",
            "Epoch 113/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8500 - loss: 0.7971\n",
            "Epoch 114/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8537 - loss: 0.7912\n",
            "Epoch 115/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8483 - loss: 0.7998\n",
            "Epoch 116/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8497 - loss: 0.7958\n",
            "Epoch 117/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8544 - loss: 0.7897\n",
            "Epoch 118/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8543 - loss: 0.7920\n",
            "Epoch 119/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8517 - loss: 0.7956\n",
            "Epoch 120/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8527 - loss: 0.7890\n",
            "Epoch 121/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8526 - loss: 0.7907\n",
            "Epoch 122/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.8520 - loss: 0.7925\n",
            "Epoch 123/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8525 - loss: 0.7896\n",
            "Epoch 124/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8536 - loss: 0.7911\n",
            "Epoch 125/150\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.8564 - loss: 0.7794\n",
            "Epoch 126/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8547 - loss: 0.7876\n",
            "Epoch 127/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8555 - loss: 0.7870\n",
            "Epoch 128/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8567 - loss: 0.7845\n",
            "Epoch 129/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8546 - loss: 0.7937\n",
            "Epoch 130/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8589 - loss: 0.7757\n",
            "Epoch 131/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8576 - loss: 0.7821\n",
            "Epoch 132/150\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.8572 - loss: 0.7848\n",
            "Epoch 133/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8564 - loss: 0.7841\n",
            "Epoch 134/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8543 - loss: 0.7882\n",
            "Epoch 135/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8569 - loss: 0.7816\n",
            "Epoch 136/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8571 - loss: 0.7835\n",
            "Epoch 137/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8568 - loss: 0.7863\n",
            "Epoch 138/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8561 - loss: 0.7878\n",
            "Epoch 139/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8580 - loss: 0.7792\n",
            "Epoch 140/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8588 - loss: 0.7852\n",
            "Epoch 141/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8566 - loss: 0.7838\n",
            "Epoch 142/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8593 - loss: 0.7824\n",
            "Epoch 143/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8593 - loss: 0.7818\n",
            "Epoch 144/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8577 - loss: 0.7897\n",
            "Epoch 145/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.8567 - loss: 0.7823\n",
            "Epoch 146/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8609 - loss: 0.7784\n",
            "Epoch 147/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8594 - loss: 0.7832\n",
            "Epoch 148/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8603 - loss: 0.7838\n",
            "Epoch 149/150\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.8618 - loss: 0.7732\n",
            "Epoch 150/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.8627 - loss: 0.7770\n",
            "157/157 - 1s - 9ms/step - accuracy: 0.6449 - loss: 1.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7500290870666504, 0.6449000239372253]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hi**"
      ],
      "metadata": {
        "id": "TCYe5ZyBwtMs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HU6immkYwvUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}